name: Use bazel remote cache service container
on:
  workflow_dispatch:
    inputs:
      docker_image:
        description: "Docker image for remote cache service container"
        required: true
        default: buchgr/bazel-remote-cache:latest
  push:
    branches: [ main ]
env:
  IMG: ${{ inputs.docker_image || 'buchgr/bazel-remote-cache:latest' }}
  USR: ${{ github.repository_owner }}
  PW: ${{ secrets.GITHUB_TOKEN }}
permissions:
  actions: read
  contents: read
  issues: read
  packages: write
  pages: read
  pull-requests: read
  repository-projects: read
jobs:
  service-container-test-job:
    runs-on: ubuntu-latest
    services:
      bazel-remote-cache:
        # TODO: Can this be configured using variables defined in repo/org?
        #       At least using env variables does not work
        image: buchgr/bazel-remote-cache:latest
        env: 
          BAZEL_REMOTE_MAX_SIZE: "10"
          BAZEL_REMOTE_ENABLE_ENDPOINT_METRICS: "true"
          BAZEL_REMOTE_DIR: "/data"
          BAZEL_REMOTE_HTTP_ADDRESS: ":8080"
          BAZEL_REMOTE_PROFILE_ADDRESS: ":6060"
        ports: 
          - 9090:8080
          - 9092:9092
          - 9050
          - 9060/tcp
    steps:
      - name: Get user details
        run: |
          whoami
          id -u $(whoami)
      - name: Get remote cache service container details
        run: |
          echo "Container id: $CONTAINER_ID
          echo "Ports id: $PORTS
          docker ps
          docker inspect $CONTAINER_ID
        env:
          PORTS: ${{ fromJSON(job.services.bazel-remote-cache.ports) }}
          CONTAINER_ID: ${{ job.services.bazel-remote-cache.id }}
      - name: Get remote cache status
        run: curl localhost:9090/status
  docker-pull-test-job:
    runs-on: ubuntu-latest
    steps:
      - name: Get user details
        run: |
          whoami
          id -u $(whoami)
      - name: Pull remote cache docker image
        run: docker pull $IMG
      - name: Start remote cache docker container
        shell: bash
        run: |
          set -eou pipefail
          echo "Starting remote cache Docker container"
          userid=$(id -u $(whoami))
          mkdir -p remote_cache_data
          chmod 777 ./remote_cache_data
          set -x
          # TODO In case this workflow runs on a single vm where multiple runners are being operated then creating
          # this Docker container multiple times with the same ports will not work. Because of that http and grpc ports
          # that are free must be identified first OR some algorithm defined that no conflicts are happening
          http_port=9090
          grpc_port=9092
          containerid=$(docker run -d -u ${userid}:1000 -v $(pwd)/remote_cache_data:/data -p ${http_port}:8080 -p ${grpc_port}:9092 buchgr/bazel-remote-cache --max_size 10 --enable_endpoint_metrics)
          set +x
          sleep 5
          docker container list
          echo "containerid=$containerid" >> $GITHUB_ENV
      - name: Get remote cache status
        run: curl localhost:9090/status
      - name: Run some code that uses the remote cache
        run: echo "Running some code"
      - name: Stop remote cache docker container
        if: ${{ env.containerid }}
        run: |
          echo "Stopping remote cache Docker container with id $containerid "
          docker container stop $containerid || true
      - name: Get remote cache status
        run: curl localhost:9090/status || true
          
