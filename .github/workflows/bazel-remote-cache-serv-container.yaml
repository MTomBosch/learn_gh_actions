name: Use bazel remote cache service container
on:
  workflow_dispatch:
    inputs:
      docker_image:
        description: "Docker image for remote cache service container"
        required: true
        default: buchgr/bazel-remote-cache:latest
  push:
    branches: [ main ]
env:
  IMG: ${{ inputs.docker_image || 'buchgr/bazel-remote-cache:latest' }}
  USR: ${{ github.repository_owner }}
  PW: ${{ secrets.GITHUB_TOKEN }}
permissions:
  actions: read
  contents: read
  issues: read
  packages: write
  pages: read
  pull-requests: read
  repository-projects: read
jobs:
  service-container-test-job:
    runs-on: ubuntu-latest
    services:
      bazel-remote-cache:
        # TODO: Can this be configured using variables defined in repo/org?
        #       At least using env variables does not work
        image: buchgr/bazel-remote-cache:latest
        # "runner" is the user name on GH managed action runners, but it cannot be used here somehow
        # uid is 1001 for std and large runners but might be different for other custom runners
        #options: "-u 1001:1001"
        # With this setting the container aborts soon after startup because it cannot write the default folder structure to
        # the data folder "_bazel_remote_cache_data" defined below because this folder is created by "root" user.
        
        # Needs to be root as the initial data folder _bazel_remote_cache_data is created by the root user
        # and there is no way to change the permissions for this folder between its creation and the docker container startup
        options: "-u root"
        env: 
          BAZEL_REMOTE_MAX_SIZE: "10"
          BAZEL_REMOTE_ENABLE_ENDPOINT_METRICS: "true"
          BAZEL_REMOTE_DIR: "/data"
          BAZEL_REMOTE_HTTP_ADDRESS: ":8080"
          BAZEL_REMOTE_PROFILE_ADDRESS: ":6060"
        ports: 
          - 9090:8080
          - 9092:9092
          # Use following two entries to get an free port mapped to the internal ports.
          # But then the usd ports must be identifed using docked inspect command
          # This is required very likely if in future one vm can run multiple gh action runner and all the runners share the ports of the vm
          #- 8080 (http end point port)
          #- 9092 (grpc end point)
        volumes:
          - ${{ github.workspace }}/_bazel_remote_cache_data:/data:rshared
      bazel-remote-cache-no-volume:
        # TODO: Can this be configured using variables defined in repo/org?
        #       At least using env variables does not work
        image: buchgr/bazel-remote-cache:latest
        # "runner" is the user name on GH managed action runners, but it cannot be used here somehow
        # uid is 1001 for std and large runners but might be different for other custom runners
        # options: "-u 1001" # With this user the container startup fails because the /data folder is not writable
        options: "-u root"
        env: 
          BAZEL_REMOTE_MAX_SIZE: "10"
          BAZEL_REMOTE_ENABLE_ENDPOINT_METRICS: "true"
          BAZEL_REMOTE_DIR: "/data"
          BAZEL_REMOTE_HTTP_ADDRESS: ":8080"
          BAZEL_REMOTE_PROFILE_ADDRESS: ":6060"
        ports: 
          - 9190:8080
          - 9192:9092
    steps:
      - name: Make bazel remote cache folder writable (sudo required)
        run: |
          set -x
          sudo chmod -R 777 ${{ github.workspace }}/_bazel_remote_cache_data
      - name: Get user and workspace details
        run: |
          whoami
          id -u $(whoami)
          pwd
          ls -l

      - name: Get remote cache service container details
        run: |

          echo "ls -l _bazel_remote_cache_data"
          ls -l _bazel_remote_cache_data
          
          echo "Container id 1: $CONTAINER_ID"
          echo "Container id 2: $CONTAINER_ID_2"
          echo "Running docker ps"
          docker ps

          echo "Running docker inspect"
          docker inspect $CONTAINER_ID
          docker inspect $CONTAINER_ID_2

          echo "Showing container log files"
          sudo find /var/lib/docker/containers/ -name "*.log" -exec cat {} \;
        env:
          CONTAINER_ID: ${{ job.services.bazel-remote-cache.id }}
          CONTAINER_ID_2: ${{ job.services.bazel-remote-cache-no-volume.id }}
      - name: Get remote cache status
        run: |
          set +e
          set -x
          curl localhost:9090/status
          curl localhost:9190/status
      # Required at end of the job in all cases so that the workspace can be cleaned up be the gha runner user during cleanup operations
      - name: Make bazel remote cache folder writable (sudo required)
        run: |
          set -x
          sudo chmod -R 777 ${{ github.workspace }}/_bazel_remote_cache_data
        if: ${{ always() }}
      - name: Export Docker container to tar file and create new image out of it
        run: |
          # Must only export the container bazel-remote-cache-no-volume as the data from volume mounts (in container bazel-remote-cache) are not exported  
          docker export --output="${TEMP}/bazel-remote-cache-no-volume.tar" $CONTAINER_ID_2
          ls -l ${TEMP}/bazel-remote-cache-no-volume.tar
          docker image import ${TEMP}/bazel-remote-cache-no-volume.tar ghcr.io/${{ github.repository_owner }}/my-bazel-remote-cache:latest
          docker image list
        env:
          CONTAINER_ID_2: ${{ job.services.bazel-remote-cache-no-volume.id }}
          TEMP: ${{ runner.temp }}
      - name: Login to GitHub Container Registry
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}
      - name: Push Docker image
        run: |
          docker push ghcr.io/${{ github.repository_owner }}/my-bazel-remote-cache:latest

#      - name: Build and push Docker images
#        uses: docker/build-push-action@ccc2b40e9ea6518f9252a22a990f8e868370f62e # v6.18.0
#        with:
#          tags: ghcr.io/${{ github.repository_owner }}/my-bazel-remote-cache:latest
#          platforms: linux/amd64 # TODO: add multi arch "linux/amd64,linux/arm64"
#          push: true
          
  docker-pull-test-job:
    if: ${{ inputs.never }}
    runs-on: ubuntu-latest
    steps:
      - name: Get user details
        run: |
          whoami
          id -u $(whoami)
      - name: Pull remote cache docker image
        run: docker pull $IMG
      - name: Start remote cache docker container
        shell: bash
        run: |
          set -eou pipefail
          echo "Starting remote cache Docker container"
          userid=$(id -u $(whoami))
          mkdir -p remote_cache_data
          chmod 777 ./remote_cache_data
          set -x
          # TODO In case this workflow runs on a single vm where multiple runners are being operated then creating
          # this Docker container multiple times with the same ports will not work. Because of that http and grpc ports
          # that are free must be identified first OR some algorithm defined that no conflicts are happening
          http_port=9090
          grpc_port=9092
          # Todo: Use --rm flag to remove the container data and its volumes from the docker storage after it stops?
          containerid=$(docker run  -d -u ${userid} -v $(pwd)/remote_cache_data:/data -p ${http_port}:8080 -p ${grpc_port}:9092 buchgr/bazel-remote-cache --max_size 10 --enable_endpoint_metrics)
          set +x
          sleep 5
          docker container list
          echo "containerid=$containerid" >> $GITHUB_ENV
      - name: Get remote cache status
        run: curl localhost:9090/status
      - name: Run some code that uses the remote cache
        run: echo "Running some code"
      - name: Stop remote cache docker container
        if: ${{ env.containerid }}
        run: |
          echo "Stopping remote cache Docker container with id $containerid "
          docker container stop $containerid || true
      - name: Get remote cache status
        run: curl localhost:9090/status || true
          
